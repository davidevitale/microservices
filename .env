# LLM Configuration
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.2:1b

# API Configuration
API_HOST=0.0.0.0
API_PORT=8003
API_RELOAD=true
API_LOG_LEVEL=info

# Service Metadata
SERVICE_NAME=agent3-spec-generator
SERVICE_VERSION=1.0.0